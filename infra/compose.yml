name: lakehouse

services:
  minio:
    image: minio/minio:latest
    container_name: minio
    environment:
      MINIO_ROOT_USER: ${ADMIN_USER}
      MINIO_ROOT_PASSWORD: ${ADMIN_PASSWORD}
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio_data:/data
    command: server --address ":9000" /data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://minio:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
    networks:
      - network
  minio_init:
    image: minio/mc:latest
    container_name: minio_mc
    depends_on:
      minio:
        condition: service_healthy
    networks:
      - network
    volumes:
    - ./minio/init:/init
    entrypoint: ["/bin/sh", "/init/create_buckets.sh"]
    environment:
      MINIO_SERVER_URL: ${MINIO_SERVER_URL}
      MINIO_ACCESS_KEY: ${ADMIN_USER}
      MINIO_SECRET_KEY: ${ADMIN_PASSWORD}
      MINIO_BUCKET_NAME: ${MINIO_BUCKET_NAME}

  nessie: 
    image: projectnessie/nessie:latest
    container_name: nessie
    environment:
      QUARKUS_HTTP_PORT: 19120
      NESSIE_VERSION_STORE_TYPE: ROCKSDB
    ports:
      - "19120:19120"
    volumes:
      - nessie_data:/data
    networks:
      - network
  jupyter:
    build:
      context: ./jupyter
    container_name: jupyter
    environment:
      MINIO_ROOT_USER: ${ADMIN_USER}
      MINIO_ROOT_PASSWORD: ${ADMIN_PASSWORD}
      MINIO_SERVER_URL: ${MINIO_SERVER_URL}
      NESSIE_SERVER_URL: ${NESSIE_SERVER_URL}
      MINIO_BUCKET_NAME: ${MINIO_BUCKET_NAME}
      NESSIE_CATALOG_NAME: ${NESSIE_CATALOG_NAME}
    ports:
      - "8888:8888"
    volumes:
      - ../data_engineering/notebooks:/home/jovyan/work
      - ./jupyter/spark_session.py:/home/jovyan/spark_session.py
    networks:
      - network
    depends_on:
      - minio
      - nessie
    command: >
      start-notebook.sh
      --ServerApp.ip=0.0.0.0
      --ServerApp.base_url=/
      --ServerApp.allow_origin='https://notebook.open-reporting.dev'
      --ServerApp.trust_xheaders=True
      --ServerApp.allow_remote_access=True
      --ServerApp.password=${JUPYTER_HASH}

  trino:
    image: trinodb/trino:latest
    container_name: trino
    ports:
      - "8081:8080"  # Map Trino's default port to 8081 to avoid conflicts
    healthcheck:
      test: ["CMD", "trino", "--server", "http://localhost:8080", "--execute", "SELECT 1"]
      interval: 30s
      timeout: 20s
      retries: 10
      start_period: 60s
    environment:
      TRINO_NODE_ID: trino-node
      TRINO_HTTP_PORT: 8080
      TRINO_DISCOVERY_SERVER_ENABLED: "true"
      ADMIN_USER: ${ADMIN_USER}
      ADMIN_PASSWORD: ${ADMIN_PASSWORD}
      MINIO_ROOT_USER: ${ADMIN_USER}
      MINIO_ROOT_PASSWORD: ${ADMIN_PASSWORD}
      MINIO_SERVER_URL: ${MINIO_SERVER_URL}
      NESSIE_SERVER_URL: ${NESSIE_SERVER_URL}
      CATALOG_URL: ${CATALOG_URL}
    volumes:
      - trino_data:/data
      - ./trino/config.properties:/etc/trino/config.properties:ro
      - ./trino/tables.properties:/etc/trino/catalog/tables.properties:ro
      - ./trino/password.db:/etc/trino/password.db
      - ./trino/password-authenticator.properties:/etc/trino/password-authenticator.properties:ro
    networks:
      - network  # Custom network for the container
    depends_on:
      - minio
      - nessie
      - jupyter
  trino_init:
    image: trinodb/trino:latest
    depends_on:
      trino:
        condition: service_healthy
    volumes:
      - ./trino/init_namespaces.sql:/init_namespaces.sql
    entrypoint: ["/bin/sh", "-c", "trino --server trino:8080 --execute \"$(cat /init_namespaces.sql)\""]
    networks:
      - network

  dbt:
    build:
      context: ./dbt   # Dockerfile for dbt image
      dockerfile: Dockerfile
    container_name: dbt
    working_dir: /usr/app
    volumes:
      - ../data_engineering/dbt:/usr/app   # mount project here
    environment:
      DBT_PROFILES_DIR: /usr/app
    command: ["tail", "-f", "/dev/null"]
    depends_on:
      - trino
    networks:
      - network
  metabase:
    image: metabase/metabase:latest
    container_name: metabase
    restart: always
    environment:
      - MB_DB_TYPE=postgres
      - MB_DB_DBNAME=metabase
      - MB_DB_PORT=5432
      - MB_DB_USER=admin
      - MB_DB_PASS=password
      - MB_DB_HOST=database
    depends_on:
      - database
    networks:
      - network

  database:
    image: postgres:14
    container_name: database
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: postgres
    volumes:
      - database_data:/var/lib/postgresql/data
      - ./database/init-metabase.sql:/docker-entrypoint-initdb.d/init-metabase.sql:ro
    networks:
      - network
  nginx:
    image: nginx:latest
    container_name: nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/conf.d:/etc/nginx/conf.d
      - ./nginx/certs:/etc/letsencrypt
      - ./nginx/www:/var/www/certbot
      - ./nginx/.htpasswd:/etc/nginx/.htpasswd
    depends_on:
      - minio
      - nessie
      - jupyter
      - trino
      - metabase
    networks:
      - network

  certbot:
    image: certbot/certbot:latest
    container_name: certbot
    volumes:
      - ./nginx/certs:/etc/letsencrypt
      - ./nginx/www:/var/www/certbot
    entrypoint: "/bin/sh -c 'trap exit TERM; while :; do sleep 12h & wait $${!}; certbot renew --webroot -w /var/www/certbot; done;'"
    depends_on:
      - nginx
    networks:
      - network

  dagster_db:
    image: postgres:14
    container_name: dagster_db
    environment:
      POSTGRES_USER: dagster
      POSTGRES_PASSWORD: dagster
      POSTGRES_DB: dagster
    volumes:
      - dagster_db_data:/var/lib/postgresql/data
    networks:
      - network

  dagster_code:
    build:
      context: ./dagster
    container_name: dagster_code
    environment:
      DAGSTER_HOME: /app/infra/dagster
      MINIO_SERVER_URL: ${MINIO_SERVER_URL}
      ADMIN_USER: ${ADMIN_USER}
      ADMIN_PASSWORD: ${ADMIN_PASSWORD}
      TRINO_HOST: trino
      TRINO_PORT: 8080
    volumes:
      - ../:/app   # mount the repo root
    command: >
      bash -lc "dagster api grpc -h 0.0.0.0 -p 4000 -m orchestration.repos"
    depends_on:
      - dagster_db
    networks:
      - network

  dagster_webserver:
    build:
      context: ./dagster
    container_name: dagster_webserver
    environment:
      DAGSTER_HOME: /app/infra/dagster
    ports:
      - "3000:3000"
    volumes:
      - ../:/app
    command: >
      bash -lc "dagster-webserver -h 0.0.0.0 -p 3000 -w /app/infra/dagster/workspace.yaml"
    depends_on:
      - dagster_code
      - dagster_db
    networks:
      - network

  dagster_daemon:
    build:
      context: ./dagster
    container_name: dagster_daemon
    environment:
      DAGSTER_HOME: /app/infra/dagster
      PYTHONUNBUFFERED: "1"
    working_dir: /app
    volumes:
      - ../:/app                      # repo root (since you run compose from infra/)
    entrypoint: []                    # run the binary directly (no shell)
    command: ["dagster-daemon","run","--log-level","DEBUG","-w","/app/infra/dagster/workspace.yaml"]
    depends_on:
      - dagster_code
      - dagster_webserver
      - dagster_db
    networks:
      - network

networks:
  network:
    driver: bridge
    
volumes:
  minio_data:
    driver: local
  nessie_data:
    driver: local
  jupyter_data:
    driver: local
  trino_data:
    driver: local
  database_data:
    driver: local
  dagster_db_data:
    driver: local
